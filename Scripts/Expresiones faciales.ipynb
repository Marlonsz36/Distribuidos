{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto de Redes de Sensores\n",
    "### Author: Marlon Segarra\n",
    "### Paralelo#1\n",
    "### Grupo #6\n",
    "### TÃ©rmino 2019-1S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definicion de ruta de imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train' #Bored and attentive images path\n",
    "validation_data_dir = 'data/validation' #Bored and attentive validation images path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis del contenido de las carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n",
      "  \n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model type\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 50 #Number of iterations for the model\n",
    "nb_train_samples = 42 #Number of train samples for the model\n",
    "nb_validation_samples = 20 #Number of validation samples for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=2, epochs=50, validation_steps=20)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.7291 - acc: 0.3990 - val_loss: 0.6986 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.7259 - acc: 0.5000 - val_loss: 0.6939 - val_acc: 0.6000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6657 - acc: 0.6260 - val_loss: 0.6909 - val_acc: 0.6500\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 22s 11s/step - loss: 0.6641 - acc: 0.6385 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.7125 - acc: 0.3750 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6877 - acc: 0.5798 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6508 - acc: 0.5462 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 12s 6s/step - loss: 0.6682 - acc: 0.5625 - val_loss: 0.6831 - val_acc: 0.5500\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.7810 - acc: 0.2942 - val_loss: 0.6804 - val_acc: 0.6000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6683 - acc: 0.5923 - val_loss: 0.6777 - val_acc: 0.6500\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.6250 - acc: 0.6875 - val_loss: 0.6796 - val_acc: 0.6000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6828 - acc: 0.5548 - val_loss: 0.6799 - val_acc: 0.5500\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6914 - acc: 0.4688 - val_loss: 0.6764 - val_acc: 0.6000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6397 - acc: 0.6260 - val_loss: 0.6722 - val_acc: 0.6500\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6390 - acc: 0.7269 - val_loss: 0.6708 - val_acc: 0.6500\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6096 - acc: 0.7731 - val_loss: 0.6730 - val_acc: 0.6000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6691 - acc: 0.5938 - val_loss: 0.6734 - val_acc: 0.6000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5747 - acc: 0.7394 - val_loss: 0.6740 - val_acc: 0.6000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5850 - acc: 0.8192 - val_loss: 0.6750 - val_acc: 0.5500\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5639 - acc: 0.8404 - val_loss: 0.6666 - val_acc: 0.6000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.5252 - acc: 0.8438 - val_loss: 0.6584 - val_acc: 0.6500\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5805 - acc: 0.7019 - val_loss: 0.6582 - val_acc: 0.6000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5425 - acc: 0.7519 - val_loss: 0.6541 - val_acc: 0.6500\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 11s 5s/step - loss: 0.5972 - acc: 0.6562 - val_loss: 0.6513 - val_acc: 0.6500\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 11s 5s/step - loss: 0.5921 - acc: 0.6875 - val_loss: 0.6465 - val_acc: 0.6000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5040 - acc: 0.7269 - val_loss: 0.6529 - val_acc: 0.6000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.4946 - acc: 0.8404 - val_loss: 0.6563 - val_acc: 0.6000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 11s 5s/step - loss: 0.5515 - acc: 0.7731 - val_loss: 0.6710 - val_acc: 0.6000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.5485 - acc: 0.7188 - val_loss: 0.6725 - val_acc: 0.6000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5954 - acc: 0.7394 - val_loss: 0.6567 - val_acc: 0.6000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 11s 5s/step - loss: 0.4889 - acc: 0.8125 - val_loss: 0.6409 - val_acc: 0.7000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5389 - acc: 0.7731 - val_loss: 0.6411 - val_acc: 0.7000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5291 - acc: 0.8529 - val_loss: 0.6490 - val_acc: 0.6500\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 12s 6s/step - loss: 0.4975 - acc: 0.7817 - val_loss: 0.6647 - val_acc: 0.6500\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 11s 5s/step - loss: 0.4339 - acc: 0.8865 - val_loss: 0.6960 - val_acc: 0.5500\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5160 - acc: 0.7188 - val_loss: 0.7111 - val_acc: 0.5500\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.4530 - acc: 0.8192 - val_loss: 0.6830 - val_acc: 0.6000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.5419 - acc: 0.7269 - val_loss: 0.6627 - val_acc: 0.6000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.4395 - acc: 0.8750 - val_loss: 0.6425 - val_acc: 0.6500\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.4766 - acc: 0.8404 - val_loss: 0.6352 - val_acc: 0.7000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.4277 - acc: 0.8192 - val_loss: 0.6405 - val_acc: 0.6000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.4698 - acc: 0.7188 - val_loss: 0.6457 - val_acc: 0.6000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.4400 - acc: 0.8865 - val_loss: 0.6652 - val_acc: 0.6000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.4635 - acc: 0.8125 - val_loss: 0.6634 - val_acc: 0.6000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.3654 - acc: 0.9538 - val_loss: 0.6570 - val_acc: 0.6000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 11s 5s/step - loss: 0.3743 - acc: 0.9077 - val_loss: 0.6491 - val_acc: 0.6000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 11s 5s/step - loss: 0.3339 - acc: 1.0000 - val_loss: 0.6429 - val_acc: 0.6000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.3165 - acc: 0.9202 - val_loss: 0.6486 - val_acc: 0.6000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.3779 - acc: 0.8865 - val_loss: 0.6427 - val_acc: 0.6000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.3642 - acc: 0.8750 - val_loss: 0.6405 - val_acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2713b902ac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model with weights and structure\n",
    "model.save('models/model_emotion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model with an image\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('data/bored_test.jpg', target_size=(150,150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image=test_image.reshape(1,150, 150, 3)\n",
    "\n",
    "result = model.predict_classes(test_image)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
